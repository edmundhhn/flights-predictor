{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd620e8-a42a-4601-83f7-bcfc90c424da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4e64b38-e7c9-46e8-8930-27099ac96d05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de9ca4b3-6370-44e2-be67-20511eb4ff5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We tune the hyperparameters for the GBTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3be3005-7ca0-4908-ac49-4ce97750f238",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For a more comprehsneive tuning process, we utilize k fold cross validation, with various tree sizes and maximum depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c4be63-668c-470b-8be3-74b2febd597f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e4b84a-76a9-49aa-b753-84d934b3aec3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Spark & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "920247c5-6e93-4691-8d82-effb03f5e074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9d4ddff-6658-45f5-bb10-128b0de52b66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".appName(\"linear_tune\") \\\n",
    ".config(\"spark.executor.memory\", \"8g\") \\\n",
    ".config(\"spark.driver.memory\", \"4g\") \\\n",
    ".config(\"spark.executor.cores\", \"2\") \\\n",
    ".config(\"spark.executor.instances\", \"4\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e78d533a-2320-4a2b-ac55-11c6ba4f488f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# REPLACE WITH PROCESSED DATA FILEPATH\n",
    "DATA_PATH = \"/mnt/bigdataproject/itineraries_processed.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "112a27fd-7672-41d0-a036-f791aaad63b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming df is a DataFrame you previously called .cache() or .persist() on\n",
    "# df.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f50222c-d214-4881-ac96-1068c6a0b3bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d66d7c-4160-4423-8816-53f8ca185292",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20039de1-f4ee-44c3-9c25-9a33b7dbabcc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90eb62c4-cd8d-41fe-b499-3e85faa02397",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = df.columns[:-1]\n",
    "feature_columns.remove('totalFare')\n",
    "\n",
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "# df_ass = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c6db148-dd2e-46c0-8d78-66d5d1efb787",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd61677-3a2e-4491-9107-69ec84a6b3f7",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the LinearRegression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"totalFare\")\n",
    "\n",
    "# Define the pipeline with the stages\n",
    "# Assuming 'assembler' is defined elsewhere in your code as it was implied in your initial setup\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"totalFare\", metricName=\"rmse\")\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "# Adjusting the parameters for LinearRegression\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Create CrossValidator\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n",
    "\n",
    "# Run cross-validation, assuming 'train_data' is your training dataset\n",
    "cvModel = cv.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68dac7bc-1a3c-4785-b869-e28f2c7218c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Investigate the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c163d1-ef5d-498f-911b-d7b500ebd1d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\naggregationDepth : 2\nelasticNetParam : 0.0\nepsilon : 1.35\nfeaturesCol : features\nfitIntercept : True\nlabelCol : totalFare\nloss : squaredError\nmaxBlockSizeInMB : 0.0\nmaxIter : 100\npredictionCol : prediction\nregParam : 0.01\nsolver : auto\nstandardization : True\ntol : 1e-06\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = cvModel.bestModel\n",
    "\n",
    "# Access the stages of the pipeline\n",
    "stages = best_model.stages\n",
    "\n",
    "# Access the parameters\n",
    "rf_params = stages[-1].extractParamMap()\n",
    "\n",
    "# Print the parameters\n",
    "print(\"Best Model Parameters:\")\n",
    "for param, value in rf_params.items():\n",
    "    print(param.name, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca480a2b-c6dd-43cc-b91f-7c791806e1f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We obtain the best results using a maxdepth of 15 and numtrees of 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0c217d5-eca2-4f57-b1a0-3bfad85511d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac5803dd-21d3-478a-b68e-378e1038d7c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 139.03635019386934\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data using the best model\n",
    "predictions = best_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cf702c3-e08f-45ea-9243-11e1fbc3979e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be74888c-bd80-4aa2-be75-1504d7c13c34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a2432b4-20ba-4d19-bb45-47ed9095b808",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "linear_model_tuning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
